{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from transformers import XLNetTokenizer, XLNetForSequenceClassification, BertTokenizer, BertForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Load the dataset\n",
    "file_path = 'datasets/cleaned_dataset_with_lyrics.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Data Cleaning: Feature Selection\n",
    "df = df[['lyrics', 'mood']]\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['lyrics'], df['mood'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Text Vectorization using TF-IDF\n",
    "tfidf = TfidfVectorizer(max_features=5000)\n",
    "X_train_tfidf = tfidf.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf.transform(X_test)\n",
    "\n",
    "# Machine Learning Model: SVM\n",
    "svm = SVC(kernel='linear', C=1, random_state=42)\n",
    "svm.fit(X_train_tfidf, y_train)\n",
    "y_pred_svm = svm.predict(X_test_tfidf)\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))\n",
    "print(\"SVM Accuracy:\", accuracy_score(y_test, y_pred_svm))\n",
    "\n",
    "# Prepare dataset for XLNet and BERT\n",
    "class SongDataset(Dataset):\n",
    "    def __init__(self, lyrics, labels, tokenizer, max_length):\n",
    "        self.lyrics = lyrics\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.lyrics)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        lyric = str(self.lyrics[index])\n",
    "        label = self.labels[index]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            lyric,\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.max_length,\n",
    "            return_token_type_ids=False,\n",
    "            padding='max_length',\n",
    "            return_attention_mask=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "def train_transformer_model(model_name, train_dataset, val_dataset):\n",
    "    model = model_name.from_pretrained(model_name_path, num_labels=len(df['mood'].unique()))\n",
    "\n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=8,\n",
    "        per_device_eval_batch_size=8,\n",
    "        warmup_steps=500,\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        logging_steps=10,\n",
    "        evaluation_strategy='epoch'\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        compute_metrics=compute_metrics,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    return trainer\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = np.argmax(p.predictions, axis=1)\n",
    "    return {\n",
    "        'accuracy': (preds == p.label_ids).astype(np.float32).mean().item()\n",
    "    }\n",
    "\n",
    "# Tokenizer and datasets for XLNet\n",
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained('xlnet-base-cased')\n",
    "train_dataset_xlnet = SongDataset(X_train.to_list(), y_train.to_list(), xlnet_tokenizer, max_length=128)\n",
    "val_dataset_xlnet = SongDataset(X_test.to_list(), y_test.to_list(), xlnet_tokenizer, max_length=128)\n",
    "\n",
    "# Tokenizer and datasets for BERT\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "train_dataset_bert = SongDataset(X_train.to_list(), y_train.to_list(), bert_tokenizer, max_length=128)\n",
    "val_dataset_bert = SongDataset(X_test.to_list(), y_test.to_list(), bert_tokenizer, max_length=128)\n",
    "\n",
    "# Train XLNet model\n",
    "trainer_xlnet = train_transformer_model(XLNetForSequenceClassification, train_dataset_xlnet, val_dataset_xlnet)\n",
    "trainer_bert = train_transformer_model(BertForSequenceClassification, train_dataset_bert, val_dataset_bert)\n",
    "\n",
    "# Evaluate models\n",
    "eval_results_xlnet = trainer_xlnet.evaluate()\n",
    "eval_results_bert = trainer_bert.evaluate()\n",
    "\n",
    "print(\"XLNet Evaluation Results:\")\n",
    "print(eval_results_xlnet)\n",
    "\n",
    "print(\"BERT Evaluation Results:\")\n",
    "print(eval_results_bert)\n",
    "\n",
    "# Compare results\n",
    "print(f\"SVM Accuracy: {accuracy_score(y_test, y_pred_svm)}\")\n",
    "print(f\"XLNet Accuracy: {eval_results_xlnet['eval_accuracy']}\")\n",
    "print(f\"BERT Accuracy: {eval_results_bert['eval_accuracy']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
